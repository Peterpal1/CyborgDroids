{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Peterpal1/CyborgDroids/blob/main/TextClassification.ipynb","timestamp":1708444880772}],"authorship_tag":"ABX9TyMOzA8DffOxEqiQuhG1e/f0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WYneW2KRujjV"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","#to read directory names\n","\n","import os\n"," #to work with text data for  pattern matching\n","\n","import re\n","#perform operations such as copying, moving, renaming, and deleting files and directories\n","\n","import shutil\n","import numpy as np\n","import string\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import losses"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"V0HMPj0MvvTg","outputId":"a73620c5-3210-450d-b685-629dc774bc0c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n","\n","dataset = tf.keras.utils.get_file(\n","    \"aclImdb_v1\", url,\n","    untar=True, cache_dir='.',\n","    cache_subdir=''\n","    )\n","\n","dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFi-UYTQwINL","outputId":"21a26091-4a88-4ecc-d558-c97932de2ec1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84125825/84125825 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["train_dir = os.path.join(dataset_dir,'train')"],"metadata":{"id":"UQaAAzfcz60h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(train_dir)\n","sample_file = os.path.join(train_dir,'pos/1181_9.txt')\n","with open(sample_file) as f:\n","  print(f.read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9wzjxsh0grh","outputId":"4ea8d70f-f6e8-4d69-e0f7-2799840d7863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"]}]},{"cell_type":"code","source":["remove_dir = os.path.join(train_dir,'unsup')"],"metadata":{"id":"WEPCsKTU2S5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#removing the unsup folder\n","shutil.rmtree(remove_dir)"],"metadata":{"id":"KxWHGp5W3Fju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","seed = 42\n","#data for training the model\n","raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/train',\n","    batch_size = batch_size,\n","    validation_split = 0.2,\n","    subset = 'training',\n","    seed = seed\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-mEwRof3n24","outputId":"8f831118-f0e4-4e27-8053-9c5910ecfb1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n"]}]},{"cell_type":"code","source":["#\n","for text_batch, label in raw_train_ds.take(1):\n","  for i in range(3):\n","    print(\"Review\",text_batch.numpy()[i])\n","    print(\"Label\",label_batch.numpy()[i])"],"metadata":{"id":"nU_roknL6D2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n","print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qZtRuuf8SOF","outputId":"c07944ec-d98c-4e11-c459-585cfa7868b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 0 corresponds to neg\n","Label 1 corresponds to pos\n"]}]},{"cell_type":"code","source":["#validating the model using 5000 files\n","raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n","    #from the directory train\n","    'aclImdb/train',\n","\n","    #determines the number of samples to work through\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset='validation',\n","    #Randomness of the validation\n","    seed=seed\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PotSKFHy8mVn","outputId":"2b3fbf31-be2d-456d-b1ee-554b04db3636"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"]}]},{"cell_type":"code","source":["raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/test',\n","    batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34AmgtUk-0LR","outputId":"72bc2e3b-e0ce-47a7-e747-94d091d399dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["#Standardizing\n","#Removing html tags and replacing <br /> with blankspaces\n","def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","  return tf.strings.regex_replace(stripped_html,\n","                                  '[%s]' % re.escape(string.punctuation),\n","                                  '')"],"metadata":{"id":"gZq2hnlK_FU2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#max length of review\n","max_features = 10000\n","sequence_length = 250\n","\n","vectorize_layer = layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode='int',\n","    output_sequence_length=sequence_length\n","    )"],"metadata":{"id":"qxiAAhYS_s8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a text-only dataset (without labels), then call adapt\n","train_text = raw_train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(train_text)"],"metadata":{"id":"mFUPAkKHPFg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vectorize_text(text, label):\n","  text = tf.expand_dims(text, -1)\n","  return vectorize_layer(text), label"],"metadata":{"id":"FNOiH2ROPTLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# retrieve a batch (of 32 reviews and labels) from the dataset\n","text_batch, label_batch = next(iter(raw_train_ds))\n","first_review, first_label = text_batch[0], label_batch[0]\n","print(\"Review\", first_review)\n","print(\"Label\", raw_train_ds.class_names[first_label])\n","print(\"Vectorized review\", vectorize_text(first_review, first_label))"],"metadata":{"id":"JUglVgKyPfjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n","print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n","print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"],"metadata":{"id":"Uh0UuG8bPiLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)"],"metadata":{"id":"rsjiRya5Pm2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"G1OLP2LNPrNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 16"],"metadata":{"id":"SA3Rvv51PuCG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","  layers.Embedding(max_features, embedding_dim),\n","  layers.Dropout(0.2),\n","  layers.GlobalAveragePooling1D(),\n","  layers.Dropout(0.2),\n","  layers.Dense(1)])\n","\n","model.summary()"],"metadata":{"id":"3IT-L2H4Pwwu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n","              optimizer='adam',\n","              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"],"metadata":{"id":"vL22o2r_PzSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=epochs)"],"metadata":{"id":"dxUiIcQCP4KR"},"execution_count":null,"outputs":[]}]}